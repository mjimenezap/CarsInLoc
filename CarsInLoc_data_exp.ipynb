{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook aims to extract general features and to check the quality of the dataset.\n",
    "# As it can be seen, the quality of the data is really good and all the values seems to be between a normal range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRARIES\n",
    "import pyspark\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, LongType\n",
    "from pyspark.sql.functions import mean, min, max\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE DATASET\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"sample_table.csv\")\n",
    "\n",
    "#  The original file can be found in \n",
    "#  https://www.kaggle.com/doit-intl/autotel-shared-car-locations\n",
    "\n",
    "#Preview of the dataset\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from https://stackoverflow.com/questions/35243744/get-specific-row-from-spark-dataframe\n",
    "\n",
    "# Function to get rows at `rownums`\n",
    "def getrows(df, rownums=None):\n",
    "    return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows at positions 0 and 2.\n",
    "print(getrows(df, rownums=[2532087]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFORMATION ABOUT THE DATA SET\n",
    "\n",
    "#Number of rows\n",
    "print('The number of rows is: ' + str(df.count()))\n",
    "\n",
    "#Number of different time stamps\n",
    "timestamps = df.groupby('timestamp').agg(f.count('timestamp').alias('count'))\n",
    "print('The number of different timestamps is: ' + str(timestamps.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of different cars\n",
    "max_size = 0\n",
    "small_list_size = 100\n",
    "\n",
    "cars_list  = df.select(\"carsList\").rdd.flatMap(lambda x: x).collect() \n",
    "cars_small_lists = [cars_list[x:x+small_list_size] for x in range(0, len(cars_list), small_list_size )] #Divide cars list into smaller lists\n",
    "\n",
    "car_IDs= [] #Final array of car IDs \n",
    "\n",
    "for small_list in cars_small_lists:\n",
    "    for row in small_list: #For each row of the spark dataframe\n",
    "        \n",
    "        row = tuple(filter(None, row.split(',')))\n",
    "        \n",
    "        if len(row)>max_size:\n",
    "            max_size = len(row)\n",
    "        \n",
    "        for element in row: \n",
    "            #remove [] and spaces\n",
    "            element = element.replace('[', '')\n",
    "            element = element.replace(']', '')\n",
    "            element = element.replace(' ', '')\n",
    "            \n",
    "                  \n",
    "            if element in car_IDs: \n",
    "                continue\n",
    "            else:\n",
    "                car_IDs.append(element)\n",
    "\n",
    "print(\"The number of cars is: \" + str(len(car_IDs)))\n",
    "print(\"The maximum number of cars simultaneosuly in the same location is: \"+str(max_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of different locations\n",
    "number_different_locations = df.groupby('latitude','longitude').count().distinct().count()\n",
    "print(\"The number of different locations (i.e., pairs of coordinates) is: \"+str(number_different_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics about the number of cars in each location\n",
    "result = df.select([mean(\"total_cars\")])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics about the locations\n",
    "result_lat = df.select([mean(\"latitude\"), min(\"latitude\"), max(\"latitude\")])\n",
    "result_lat.show()\n",
    "result_long = df.select([mean(\"longitude\"), min(\"longitude\"), max(\"longitude\")])\n",
    "result_long.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for empty cells\n",
    "\n",
    "print(\"The number of empty cells in latitude columns is: \" + str(df.filter(\"'latitude' == ''\").count()))\n",
    "print(\"The number of empty cells in longitude columns is: \" + str(df.filter(\"'longitude' == ''\").count()))\n",
    "print(\"The number of empty cells in total_cars columns is: \" + str(df.filter(\"'total_cars' == ''\").count()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
